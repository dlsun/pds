{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.3 Distance Metrics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBgTRCHclclP",
        "colab_type": "text"
      },
      "source": [
        "# 10.3 Distance Metrics\n",
        "\n",
        "In the last section, we used Cosine Similarity to measure how similar two documents are. However, there are many other measures of similarity that exists. It will be up to us to decide which metric is best for our application. In this section, we will explore these other methods for measuring text similarity. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BO29LPWh9Bn",
        "colab_type": "text"
      },
      "source": [
        "## Hamming Distance\n",
        "\n",
        "The most simple and intuitive method for measuring string similarity is the hamming distance. Given two strings of equal lengths, it measures the number of symbols that are different at each corresponding index. Take the example of the strings `\"BRYAN\"` and `\"BRIAN\"`. Here, we can see that the Hamming difference between the two strings is 1 because they are different at one location (third letter). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhw83KbRkRC9",
        "colab_type": "code",
        "outputId": "a7706f2a-5a7c-4921-c2c2-446ab4789101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def hamming_distance(str1, str2): \n",
        "    if len(str1) != len(str2): \n",
        "        return None \n",
        "\n",
        "    differences = 0\n",
        "    for x in range(len(str1)): \n",
        "        if str1[x] != str2[x]: \n",
        "            differences += 1 \n",
        "        \n",
        "    return differences\n",
        "\n",
        "hamming_distance(\"Bryan\", \"Brian\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3B-DJ3HlO0t",
        "colab_type": "text"
      },
      "source": [
        "In theory, we can modify the Hamming Distance to accept two strings of different lengths, and whatever is left over is counted as a difference. The following is a simple implementation for this modified Hamming Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7S6HPYxlKy3",
        "colab_type": "code",
        "outputId": "9bfdfa7b-15a9-49f9-f119-8e3a6bf596a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def modified_hamming_distance(str1, str2): \n",
        "    differences = 0\n",
        "\n",
        "    if len(str1) != len(str2):\n",
        "        differences += abs(len(str1) - len(str2))\n",
        "\n",
        "    for x in range(len(str1)): \n",
        "        if str1[x] != str2[x]: \n",
        "            differences += 1 \n",
        "        \n",
        "    return differences\n",
        "\n",
        "modified_hamming_distance(\"Bryan\", \"Brian!!!\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BethmiSBoTJj",
        "colab_type": "text"
      },
      "source": [
        "## Edit Distance\n",
        "\n",
        "A more applicable string metric is the edit distance. Generally, the edit distance is the smallest number of operations needed to turn one string into another. These operations may include insertions, deletions, substitutions, transposition, etc. Edit distances have different names based on their set of operations. For this chapter, we will focus on the Damerau-Levenshtein distance.\n",
        "\n",
        "### Damerau-Levenshtein Distance\n",
        "\n",
        "The Damerau-Levenshtein distance has four operations: deletion, insertion, substitution, and transposition. Here's what these operations mean:\n",
        "\n",
        "* Deletion: **s**cat --> cat <br>\n",
        "\"scat\" and \"cat\" have an edit distance of 1 because we can delete the s in \"scat\" to turn it into \"cat\". \n",
        "\n",
        "* Insertion: at --> **m**at <br>\n",
        "\"at\" and \"mat\" have an edit distance of 1 because we can insert an m into \"at\" to turn it into \"mat\". \n",
        "\n",
        "* Substitution: **m**at --> **c**at <br>\n",
        "\"mat\" and \"cat\" have an edit distance of 1 because we can substitute the m in \"mat\" for a c to turn \"mat\" into a \"cat\".\n",
        "\n",
        "* Transposition: e**at** --> e**ta** <br>\n",
        "\"eat\" and \"eta\" have an edit distance of 1 because we can transpose the successive characters of 'a' and 't' to turn \"eat\" into \"eta\". \n",
        "\n",
        "By measuring how many steps it takes to turn one string into another, it tells us how similar the two strings are. While the concept may be simple, it is infinitely applicable. One of the more interesting applications of the Damerau-Levenshtein distance is lingustic comparison. By computing the DL distance on two strings of different language but of same meaning, we can get a general idea of how similar the two languages are. \n",
        "\n",
        "Damerau-Levenshtein distance is conceptually simple but it is rather tedious to implement efficiently as it requires Dynamic Programming. NLTK provides us with an implementation of Damerau-Levenshtein distance with the `edit_distance()` function. Note that `edit_distance()` only provides the Levenshtein distance (without transposition). To make `edit_distance()` compute Damerau-Levenshtein distance we specify the parameter `transpositions = True`.\n",
        "\n",
        "\n",
        "Below is an example of DL distance in practice using translation of an excerpt from Winston Churchill's famous \"We shall fight on the beaches\" speech into five different languages.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKge7Vi6oSR5",
        "colab_type": "code",
        "outputId": "31720555-6f7e-4da6-987a-e1365eaffd38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "from nltk.metrics import edit_distance\n",
        "import pandas as pd\n",
        "\n",
        "df_speech = pd.read_csv(\"https://raw.githubusercontent.com/bfkwong/data/master/we_shall_never_surrender.csv\", index_col=\"language\")\n",
        "\n",
        "def getDLDistance(language): \n",
        "    return edit_distance(df_speech.loc[\"english\"][\"text\"], language, transpositions=True)\n",
        "\n",
        "df_speech[\"Distance to English\"] = df_speech[\"text\"].apply(getDLDistance)\n",
        "df_speech"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Distance to English</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>language</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>english</th>\n",
              "      <td>We shall go on to the end. We shall fight in F...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spanish</th>\n",
              "      <td>Llegaremos hasta el final, lucharemos en Franc...</td>\n",
              "      <td>276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>german</th>\n",
              "      <td>Wir werden bis zum Ende weitermachen. Wir werd...</td>\n",
              "      <td>334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>portuguese</th>\n",
              "      <td>Iremos até ao fim. Lutaremos na França. Lutare...</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>french</th>\n",
              "      <td>Nous irons jusqu'au bout, nous nous battrons e...</td>\n",
              "      <td>326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>italian</th>\n",
              "      <td>ndremo avanti fino alla fine. Combatteremo in ...</td>\n",
              "      <td>292</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         text  Distance to English\n",
              "language                                                                          \n",
              "english     We shall go on to the end. We shall fight in F...                    0\n",
              "spanish     Llegaremos hasta el final, lucharemos en Franc...                  276\n",
              "german      Wir werden bis zum Ende weitermachen. Wir werd...                  334\n",
              "portuguese  Iremos até ao fim. Lutaremos na França. Lutare...                  281\n",
              "french      Nous irons jusqu'au bout, nous nous battrons e...                  326\n",
              "italian     ndremo avanti fino alla fine. Combatteremo in ...                  292"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHvsnPmzfu-A",
        "colab_type": "text"
      },
      "source": [
        "When it comes to the vocabularies in this excerpt from Churchill's speech. English is most similar to Spanish, followed by Portuguese, Italian, German, and finally French. It is important that we don't extrapolate this conclusion to the entire language, as these results only shows that with the words and punctuations used in this speech."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSKNeVzBooXL",
        "colab_type": "text"
      },
      "source": [
        "## Jaccard Distance\n",
        "\n",
        "This method of comparing string similarity is more based on statistics than pure comparison like Hamming Distance and Edit Distance. The formulation of this metric is as follows: \n",
        "\n",
        "$$\n",
        "d = 1 - {|X \\cap Y| \\over |X \\cup Y|}\n",
        "$$\n",
        "\n",
        "What this equation tells us is that given two strings, we want to find the number of characters they have in common and divide it by the number of characters in total. Then we subtract it by 1, so its is consistent with all other distance metric where the more dissimilar two strings are, the larger their distance metric. Consider the following toy example: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh_exrbztvKp",
        "colab_type": "code",
        "outputId": "340e9db4-4e95-4494-d7a5-f31df7bf987d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "documentX = \"Republic of Korea\"\n",
        "documentY = \"The Republic of Albania\"\n",
        "\n",
        "setX = set(documentX)\n",
        "setY = set(documentY)\n",
        "\n",
        "intersection = setX.intersection(setY)\n",
        "union = setX.union(setY)\n",
        "\n",
        "jaccard_dist = 1 - (len(intersection)/len(union))\n",
        "jaccard_dist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33333333333333337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQG8k-bptvfA",
        "colab_type": "text"
      },
      "source": [
        "Of course, this can be applied to words of a string as well instead of individual characters. Consider the following code:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPR7puJQuslG",
        "colab_type": "code",
        "outputId": "b1a4d95f-0530-4e8f-a742-8ab394c73995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "\n",
        "fed_1 = requests.get(\"http://dlsun.github.io/pods/data/federalist/1.txt\").text.lower()\n",
        "fed_2 = requests.get(\"http://dlsun.github.io/pods/data/federalist/2.txt\").text.lower()\n",
        "\n",
        "fed_1 = set([x for x in re.split(\"\\n| |,|\\.|\\(|\\)\", fed_1) if x != '' and x != '\"'])\n",
        "fed_2 = set([x for x in re.split(\"\\n| |,|\\.|\\(|\\)\", fed_2) if x != '' and x != '\"'])\n",
        "\n",
        "intersect = fed_1.intersection(fed_2)\n",
        "union = fed_1.union(fed_2)\n",
        "\n",
        "jaccard_dist = 1 - (len(intersect)/len(union))\n",
        "jaccard_dist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7766895200783546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OfWaiK40pp-",
        "colab_type": "text"
      },
      "source": [
        "Fortunately for us, NLTK has a Jaccard Distance implementation for us to use so that we don't have to write all this code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT_pa4cj03Xb",
        "colab_type": "code",
        "outputId": "0bab68e3-59f1-4a22-fa76-225dac2daf39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "jaccard_distance(fed_1, fed_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7766895200783546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiUHy1wPFKM0",
        "colab_type": "text"
      },
      "source": [
        "On the surface, Jaccard distance seems a bit generic, but that is what makes this such a popular metric. Its only requirement is that the inputs are two sets which means that we can compare basically anything. One additional benefits of Jaccard distance is that duplicates does not affect the results since Jaccard distance operates on sets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YALHZEiVtxO3",
        "colab_type": "text"
      },
      "source": [
        "## Building Similarity Matrix\n",
        "\n",
        "Just like in our previous section, we want to build a similarity matrix that tells us which document is most similar to which other. To create a similarity matrix $S$, we want to ensure that $S_{ij}$ gives us the similarity between string i and string j. Note that in all the formulations we have given above, 0 represent identical strings, this can of course be inverted to fit your needs. \n",
        "\n",
        "The below code generates the a similarity matrix for the languages used for the translations of \"We shall fight on the beaches\" speech\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh6l7PK5frn8",
        "colab_type": "code",
        "outputId": "d64698fa-a6bb-4536-dac1-5009489c7f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "mtrx = np.zeros((df_speech.shape[0], df_speech.shape[0]))\n",
        "for i in range(df_speech.shape[0]):\n",
        "    for j in range(i + 1, df_speech.shape[0]):\n",
        "        d = edit_distance(df_speech.iloc[i][\"text\"], df_speech.iloc[j][\"text\"])\n",
        "        mtrx[i][j] = d\n",
        "        mtrx[j][i] = d\n",
        "\n",
        "mtrx = pd.DataFrame(mtrx, index=df_speech.index, columns=df_speech.index)\n",
        "mtrx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>language</th>\n",
              "      <th>english</th>\n",
              "      <th>spanish</th>\n",
              "      <th>german</th>\n",
              "      <th>portuguese</th>\n",
              "      <th>french</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>language</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>english</th>\n",
              "      <td>0.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>293.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spanish</th>\n",
              "      <td>276.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>german</th>\n",
              "      <td>334.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>345.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>portuguese</th>\n",
              "      <td>281.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>french</th>\n",
              "      <td>328.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>288.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>italian</th>\n",
              "      <td>293.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>345.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "language    english  spanish  german  portuguese  french  italian\n",
              "language                                                         \n",
              "english         0.0    276.0   334.0       281.0   328.0    293.0\n",
              "spanish       276.0      0.0   338.0       130.0   280.0    220.0\n",
              "german        334.0    338.0     0.0       344.0   368.0    345.0\n",
              "portuguese    281.0    130.0   344.0         0.0   280.0    190.0\n",
              "french        328.0    280.0   368.0       280.0     0.0    288.0\n",
              "italian       293.0    220.0   345.0       190.0   288.0      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP0zNA9Svyb4",
        "colab_type": "text"
      },
      "source": [
        "This similarity matrix tells us how similar languages are to each other. It makes sense for this matrix to suggest that Spanish is more similar to Portuguese and Italian than English, French, or German. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUmS6CXZwtdT",
        "colab_type": "text"
      },
      "source": [
        "# Exercises "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3K2dw5oCd2Z",
        "colab_type": "text"
      },
      "source": [
        "1. Autocorrects determine if a word is correct by comparing it to an existing list of words. Download a dictionary of words from (https://raw.githubusercontent.com/dwyl/english-words/master/words_dictionary.json) and write a function that takes in a string and determine if there are any misspelling using the Hamming Distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3tY5LkR4qVY",
        "colab_type": "text"
      },
      "source": [
        "2. Damerau-Levenshtein distance is often used to measure how similar two RNA/DNA sequences are. Download the data from (link) and determine which animal HIV came from.\n",
        "\n",
        "    Note: It may take a while to calculate Damerau-Levenshtein distance for long sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDt8YbtoHhlP",
        "colab_type": "text"
      },
      "source": [
        "3. Use the Jaccard distance to create a similarity matrix for translations of Churchill's speeches. Can you see any advantages or disadvantages of using the Jaccard distance in this context?"
      ]
    }
  ]
}